[step_1]
label = "Easy Agent Configuration"
content = """
LLMling-agent excels at static YAML-based agent configuration:

- Define agents in not-seen-yet detail in pure YAML (pydantic-backed)
- Expansive YAML schema for linters for providing maxium help setting up YAML files
- Agent "connection" setup via YAML allowing simple workflows without having to use a step-based appraoch
- Result type definitions via YAML (StructuredAgents)
- Configuration inheritance and reuse
- Environment/tools/resource configuration
- Extensive schema validation and linting
- Type-safe structured responses
"""

[step_2]
label = "True Async Framework"
content = """
An async-first Agent framwork.
Unlike most other frameworks, where async is only done at a workflow-step level,
this framework is async-first in its design.

Built for modern async Python from the ground up.

- Proper async context management
- Non-blocking operations
- Streaming responses
- Resource cleanup
- Background task handling
- Parallel initialization
- Automatic resource management
"""

[step_3]
label = "Type-Safety on Pydantic-Level"
content = """

- Excellently typed user APIs
- A lot of love in detail to provide maximum type safety
- Type-safe message passing
- Type-safe Agent-Team forming
- Type-safe task execution
- Structured response handling
- Flexible routing options
- Cost and token tracking
"""

[step_4]
label = "Pool-Based Architecture"
content = """
Central coordination point for multi-agent systems:

- Type-safe dependency injection
- Shared resource management
- Session and history management
- Dynamic agent / team creation/cloning
- Agent discovery and access control
- Central monitoring and statistics
- Common storage configuration
"""

[step_5]
label = "Provider Architecture"
content = """
Flexible provider system decoupling agent logic from AI implementation.
Humans, LLM libraries and Callables can all be used as the "Agent" brain and be switched flawlessly, allowing unique AI-Human interactions.

- Modular provider architecture
- First-class Pydantic-AI support (recommended)
- LiteLLM integration for model variety
- Human-in-the-loop provider
- Custom provider support
- Callable provider
- UI/Observer integration
- Consistent interface across providers
- Provider-specific optimizations
- Stream support
- Multi-modal support for LitemLLM (experimental)
"""

[step_6]
label = "Teams and Execution"
content = """
Flexible team operations and execution patterns:

- Multiple execution modes (parallel/sequential)
- Rich monitoring capabilities
- Connection mechanisms (>>, &, |)
- Type-safe team creation
- Execution statistics and cost tracking
- Background execution with monitoring
"""


[step_7]
label = "MCP server integration"
content = """
MCP server support for Agents.

- Agents with MCP server configurations will "connect" on async initialization
- MCP severs can provide agent tools
- More extensive coverage of the MCP servers soon.
"""

[step_8]
label = "Event System"
content = """
React to changes and automate workflows:

- File system monitoring with patterns
- Webhook endpoints (coming soon)
- Configurable event debouncing
- Event filtering and routing
- Custom trigger types
- Automatic context loading
- Event-driven agent execution
"""

[step_9]
label = "Command System"
content = """
Rich command system across all interfaces:

- Unified command system
- Tool management commands
- Resource inspection
- Model configuration
- History access and search
- Runtime configuration
- Session management
- Cross-interface consistency
"""

[step_10]
label = "Database & Logging"
content = """
Comprehensive interaction tracking:

- Multiple storage providers
- Configurable logging levels
- Message history tracking
- Maximum flexibility in formatting conversations
- Tool usage monitoring
- Cost and token tracking
- Query capabilities
- Session recovery
- Flexible storage backends
- Sophisticated conversation filtering for agents
"""

[step_11]
label = "Interaction Patterns"
content = """
Rich patterns for agent interaction and collaboration:

- Automatic and human-in-the-loop decisions
- Concurrent agent execution
- Non-blocking forwarding mechanisms
- Blocking when needed (await_response)
- Automatic result routing (>>)
- Team formation helper (pick)
- Message broadcasting
- Priority-based routing
- Delayed forwarding
- Connection monitoring
"""


[step_12]
label = "Multi-modal support"
content = """
Both LiteLLM and Pydantic-AI (using a workaround) support Image input.
Additional content types will be integrated soon!
"""

[step_13]
label = "Multiple Interfaces"
content = """
Multiple ways to interact:

- Rich CLI interface using prompt-toolkit with expansive command system
- Web UI with Gradio
- Terminal UI with Textual (WIP)
- Python API
- Consistent experience
- Cross-interface features
- Unified command system
"""

[step_14]
label = "Task System"
content = """
Independent work definitions with type safety:

- Tasks define requirements, not implementations
- Type-safe dependency requirements
- Automatic tool provisioning
- Knowledge source integration
- Runtime validation
- Reusable task definitions
- YAML-based task configuration
"""

[step_15]
label = "Capability System"
content = """
Fine-grained permission control for agents:

- Automatic tool availability based on capabilities
- Granular access level management
- Resource access control
- Tool usage permissions
- History and stats access levels
- Agent interaction capabilites
"""

[step_16]
label = "Knowledge Management"
content = """
Comprehensive knowledge integration:

- Multiple knowledge sources
- Rich resource handling
- Dynamic prompt integration
- Automatic context loading
- Markdown conversion
- Token-aware context management
- Parallel resource initialization
"""
